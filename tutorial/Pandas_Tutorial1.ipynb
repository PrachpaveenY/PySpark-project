{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas\n",
    "\n",
    "Pandas เป็น Library ใน Python ที่ทำให้เราเล่นกับข้อมูลได้ง่ายขึ้น เหมาะมากสำหรับทำ Data Cleaning / Wrangling\n",
    "\n",
    "วิธีการใช้งาน Pandas คือ โหลดไฟล์ข้อมูล เช่น CSV เข้าไป แล้วเราจะได้ข้อมูลในรูปแบบตาราง (DataFrame) ที่แบ่งข้อมูลตามแถวและคอลัมน์ หรือเหมือน Excel ที่เราใช้กัน\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## เช็ค Version Pandas\n",
    "# สำคัญมากเวลาเราอ่าน Documentation เพราะถ้าเกิดมีอะไรพัง เราจะเทียบได้ว่า Pandas ของเราเป็นเวอร์ชั่นตามใน Documentation ไหม\n",
    "print (\"Pandas version\",pandas.__version__)\n",
    "\n",
    "\n",
    "## การโหลดไฟล์ CSV (Import)\n",
    "# เราสามารถใช้คำสั่ง .head หรือ .tail เพื่อดูข้อมูลแถวบนสุด หรือแถวล่างสุดได้\n",
    "# จุดเริ่มต้นของการทำ Data Exploration & Analysis ใน Pandas ก็คือการโหลดไฟล์ข้อมูลแบบ CSV มาใช้งาน\n",
    "csvdf = pd.read_csv('data.csv')                             # Read DF\n",
    "csvdf = pd.read_csv('data.csv',encoding = \"ISO-8859-1\")     # Sometimes reading CSV for Excel need encoding\n",
    "csvdf.head()                                                # Print head and tail\n",
    "csvdf.tail()                                                # Print head and tail\n",
    "\n",
    "\n",
    "## เช็คจำนวนแถว และจำนวนคอลัมน์\n",
    "csvdf.shape\n",
    "\n",
    "\n",
    "## สุ่มข้อมูลสำหรับเช็ค (Sample)\n",
    "# เราเช็คข้อมูลว่าถูกต้องมั้ยด้วย head กับ tail ซึ่งเป็นการเช็คจากด้านบนหรือด้านล่าง อีกวิธีที่น่าสนใจ คือ เช็คแบบสุ่มข้อมูลขึ้นมา\n",
    "csvdf.sample()\n",
    "\n",
    "\n",
    "## เช็คข้อมูลหาความผิดปกติใน DataFrame เบื้องต้น\n",
    "# หลังจากโหลดข้อมูลมาแล้ว เราอยากรู้ว่าข้อมูลมีกี่แถว,  Missing value เท่าไหร่, แต่ละคอลัมน์เป็น Data Type อะไรบ้าง ก็รันคำสั่งนี้ได้เลย\n",
    "# นอกจากนั้นยังมีคำสั่ง df.dtypes (ไม่มีวงเล็บ) สำหรับดู Data Type แต่ละคอลัมน์อย่างเดียว\n",
    "df.info()\n",
    "\n",
    "\n",
    "## แปลงประเภทข้อมูล (Data Type) ใน Data Frame\n",
    "# บางครั้งประเภทข้อมูลของคอลัมน์เป็น String แต่เราต้องการ Integer หรือเราต้องการ Date เราสามารถแปลงข้อมูลได้ง่ายๆ ดังนี้\n",
    "df['hour'] = pd.to_numeric(df['hour'])      # แปลงเป็น Numeric\n",
    "df['hour'] = df['hour'].astype('int')       # อีกวิธีในการแปลงค่า สามารถใช้วิธีนี้แปลงเป็น float ได้\n",
    "\n",
    "\n",
    "## เช็ค Summary ของแต่ละคอลัมน์ (count, min, max, mean)\n",
    "# ถ้าเราอยากรู้ Distribution คร่าว ๆ ของแต่ละคอลัมน์ว่าเป็นอย่างไร สามารถใช้คำสั่ง describe() ได้\n",
    "df.describe()\n",
    "\n",
    "\n",
    "## เช็ค Summary (count, min, max, mean) แบบแยกกลุ่ม\n",
    "# บางครั้งเราไม่ได้ต้องการรู้ Summary ของทั้งคอลัมน์ แต่อยากให้แยกตามแต่ละค่าในคอลัมน์นั้นๆ แล้วอยากรู้ว่าบางกลุ่มมีอะไรผิดปกติหรือเปล่า\n",
    "test = df.groupby(['Gender'])\n",
    "test.describe()\n",
    "\n",
    "\n",
    "## สร้าง DataFrame ใหม่\n",
    "# วิธีสร้างแบบง่ายที่สุด ถ้าต้องการข้อมูลหลายรูปแบบ เราสามารถใช้ Dictionary แบบนี้\n",
    "dataframe = pandas.DataFrame({\n",
    "    'C1': pandas.date_range('20170101', periods=4),\n",
    "    'C2' : [10,20,30,40],\n",
    "    'C3': pandas.Categorical(['A','B','C','D']),\n",
    "    'C4': 1})\n",
    "# แต่ถ้าเราต้องการแค่เป็นแบบตัวเลขทั่วไป ใช้ Numpy แบบนี้ได้เลย\n",
    "array = numpy.array([(1,2,3), (4,5,6),(7,8,9)])\n",
    "dataframe = pandas.DataFrame(array,columns=['C1','C2','C3'])\n",
    "\n",
    "\n",
    "## เลือกหลายคอลัมน์จาก DataFrame\n",
    "df['C1']            # ปกติถ้าเราต้องการเลือกแค่ 1 Column ก็เขียนแบบนี้ได้เลย\n",
    "df[['C1','C2']]     # แต่ถ้าต้องการเลือกหลายคอลัมน์ ให้ทำแบบนี้\n",
    "\n",
    "\n",
    "## เลือกคอลัมน์ตามเงื่อนไขที่ต้องการ\n",
    "# บางทีเราอยาก Filter เฉพาะคอลัมน์ที่มีค่าตามที่เราต้องการโดยใช้ .loc ได้ โดยสามารถเลือก Filter แบบ .all() (ทุกค่าในคอลัมน์ต้องตรงตามเงื่อนไข) หรือ .any() (บางค่าในคอลัมน์ต้องตรงตามเงื่อนไข)\n",
    "dataframe2 = dataframe.loc[:,(dataframe>50).any()]\n",
    "dataframe3 = dataframe.loc[:,(dataframe>50).all()]\n",
    "# เราสามารถใช้หาคอลัมน์ที่มี Missing Values หรือหาคอลัมน์ที่ไม่มี Missing Values เลยก็ได้\n",
    "dataframe2 = dataframe.loc[:,dataframe.isnull().any()]\n",
    "dataframe3 = dataframe.loc[:,dataframe.notnull().all()]\n",
    "\n",
    "\n",
    "## เลือกแถวตามเงื่อนไขที่ต้องการ\n",
    "dataframe[dataframe['C1']>50]                               # เงื่อนไขแบบง่าย ๆ\n",
    "dataframe2 = dataframe.loc[dataframe.C1.isin([1,2,3])]      # เงื่อนไขแบบซับซ้อน\n",
    "# ถ้ามีหลายเงื่อนไขเราสามารถใช้ & (and) หรือ | (or) ได้\n",
    "dataframe[(dataframe['C1']>50) & ((dataframe['C2']<25) | (dataframe['C2']>75))]\n",
    "# หรือใช้ Query เป็นเงื่อนไขได้ด้วย มีประโยชน์มากเวลาเรามีเงื่อนไขแปลก ๆ ไม่ต้องเขียนลูปขึ้นมาเองเลย\n",
    "dataframe2 = dataframe.query('C1 > C2')\n",
    "\n",
    "\n",
    "## เพิ่มคอลัมน์ใหม่\n",
    "# สามารถเพิ่มคอลัมน์ใหม่ได้ 2 แบบ คือ\n",
    "    # 1. เพิ่มโดยอิงจากคอลัมน์เดิม (เช่น เอาคอลัมน์เดิม + 10 หรือ เอาคอลัมน์ A – คอลัมน์ B มีประโยชน์มากตอนทำ Feature Engineering)\n",
    "    # 2. เพิ่มคอลัมน์โดยตั้งค่า Fix ไปเลยสำหรับทุกแถว ส่วนใหญ่จะใช้วิธีนี้เวลาเราอยากได้ค่าอะไรแปลก ๆ ที่ต้องเขียนลูปเพื่อใส่ค่า ก็สร้างคอลัมน์แบบ Fix ค่าก่อน แล้วต่อด้วยลูป\n",
    "df['new'] = dataframe['old'] + 10       # use old values\n",
    "df['new2'] = 5                          # apply the same value\n",
    "\n",
    "\n",
    "## การสลับ Row <-> Column (Transpose)\n",
    "# ถ้าเราต้องการ Transpose (อารมณ์เหมือน Vector) เราสามารถใช้คำสั่งนี้ได้เลย\n",
    "dataframe.T\n",
    "\n",
    "\n",
    "## การต่อ DataFrame (รวมข้อมูล DataFrame เช่น เอา CSV มาต่อกัน)\n",
    "# การต่อ Data Frame คือการเอา Data Set 2 ชุดมาต่อกันในแถวตั้งหรือแนวนอน สำหรับการต่อแบบปะติดไปเลย\n",
    "# มี 2 คำสั่งที่เหมือนกัน คือ concat กับ append แต่ให้ใช้ concat ไปเลย เพราะ append เป็นคำสั่งที่ไม่ Memory Efficient\n",
    "pd.concat([df1,df2], axis=1)                # รวมกัน 2 คอลัมน์ (axis = 0 คือแถว, axis = 1 คือคอลัมน์)\n",
    "pd.concat([df1,df2,df3)]                    # รวมมากกว่า 2 คอลัมน์ก็ได้\n",
    "pd.concat(…, ignore_index=True)             # รวมเสร็จแล้ว reset index ให้ด้วย ควรใช้ ไม่งั้นจะเจอ row ID ซ้ำกันตอนรวมร่าง\n",
    "pd.concat(…, join='inner')                  # รวมร่างเฉพาะคอลัมน์ที่ df1 กับ df2 มีทั้งคู่\n",
    "pd.concat(…, keys=['source1', 'source2'])   # เพิ่มคอลัมน์เข้าไปด้วยเพื่อระบุว่า Row แต่ละอันมาจาก Data Frame อันไหน\n",
    "pd.concat(…, join_axes=[df2.index])         # เลือกรวมร่างเฉพาะ row index ที่เรากำหนดได้\n",
    "\n",
    "\n",
    "## การต่อ DataFrame แบบ Join\n",
    "# ถ้าต้องการต่อ DataFrame แบบ Advance หน่อย เราก็สามารถ Join DataFrame ได้เหมือน Join Table\n",
    "pd.merge(df1, df2, left_on=\"col1\", right_on=\"col2\", how=\"inner\")        # เราสามารถเปลี่ยนตรง how=”inner” เป็น “outer”, “left”, “right” เพื่อเปลี่ยนเป็น Outer Join, Left Join, Right Join ได้อีกด้วย\n",
    "\n",
    "\n",
    "## การหาค่า Mean, Sum, Max (Aggregate) แบบทั้ง DataFrame\n",
    "# Pandas สามารถสั่ง Aggregate เพื่อหาค่า Mean, Sum, และ Max ได้เลย เหมาะมากเวลาเราต้องการรวบข้อมูลก่อนเอาไป Visualize หรือต้องการทำ Feature Engineering\n",
    "newdf = df.agg(['sum', 'max','mean'])\n",
    "\n",
    "\n",
    "## การ Aggregate แบบตามกลุ่มที่ต้องการ\n",
    "# บางทีเราอยาก Aggregate ข้อมูลตามการจัดกลุ่มในคอลัมน์อื่น เช่น เราอยากได้รายจ่ายทั้งหมดของแต่ละคน (ต้อง aggregate sum ของคอลัมน์รายจ่าย โดยแบ่งกลุ่มตามคอลัมน์ User ID) ใช้แบบนี้\n",
    "aggregate = dataframe.groupby('C1').sum()\n",
    "\n",
    "\n",
    "## การรัน Function เดียวกันทุกแถว หรือทุกคอลัมน์\n",
    "# เวลาเราอยากรันคำสั่งอะไรสักอย่างสำหรับทุกแถว หรือทุกคอลัมน์ เราสามารถเขียนได้แบบนี้\n",
    "sum_columns = dataframe[['C1','C2']].apply(sum,axis=0)      # sum for columns\n",
    "sum_rows = dataframe[['C1','C2']].apply(sum,axis=1)         # sum for rows\n",
    "\n",
    "\n",
    "## รันคำสั่งที่เขียนเองกับทุกแถวใน 1 คอลัมน์\n",
    "# ถ้าต้องการรันคำสั่ง (Function) ที่เขียนเอง สำหรับทุกแถวในคอลัมน์อันใดอันหนึ่ง ใช้แบบนี้ได้\n",
    "dataframe['C1'] = dataframe['C1'].map(lambda x: x-100)\n",
    "\n",
    "\n",
    "## รันคำสั่งที่เขียนเองกับทุกค่า\n",
    "# ถ้าต้องการรันคำสั่งที่เขียนเองกับทุกค่าใน DataFrame ใช้โค้ดนี้\n",
    "function_result = dataframe.applymap(lambda x: x*10)\n",
    "new_dataframe = dataframe.transform(lambda x: x*100)        # ใช้ transform\n",
    "\n",
    "\n",
    "## คำนวณ Correlation & Covariance\n",
    "# เวลาเราอยากรู้ว่าค่าต่าง ๆ ใน Data Set เรา Correlate กันมั้ย\n",
    "dataframe.corr()        # Correlation\n",
    "dataframe.cov()         # Covariance\n",
    "# แต่ค่าที่ออกมาเป็นตัวเลขอาจจะดูยากนิดนึง เราสามารถพลอตสวยๆ ด้วย Seaborn ได้ สามารถใช้โค้ดด้านล่างนี้ได้เลย\n",
    "import seaborn as sns\n",
    "corr = modeldf.corr()\n",
    "f, ax = plt.subplots(figsize=(15, 8))                       # Set up the matplotlib figure\n",
    "cmap = sns.diverging_palette(10, 10, as_cmap=True)          # Generate a custom diverging colormap\n",
    "sns.heatmap(corr, annot=True)                               # Draw the heatmap with the mask and correct aspect ratio\n",
    "\n",
    "\n",
    "## คำนวณ Cross Tabulation\n",
    "# Cross Tabulation มีประโยชน์มากเวลาเราอยากรู้ว่ามี Data ที่ตรงกับกรุ๊ป A ของคอลัมน์ 1 และกรุ๊ป B ของคอลัมน์ 2 เท่าไหร่ เช่น มีนักเรียนผู้ชาย (คอลัมน์ gender) กี่คนในมัธยมปลาย (คอลัมน์ education) แบบนี้เป็นต้น\n",
    "# คล้าย PivotTable\n",
    "aggregate = pandas.crosstab(dataframe.C1, dataframe.C2)\n",
    "\n",
    "\n",
    "## หาค่า Unique ในแต่ละคอลัมน์\n",
    "# คำสั่งนี้มีประโยชน์มาก เอาไว้ใช้เช็คว่าแต่ละคอลัมน์มีค่าแปลกๆ มั้ย\n",
    "# ตัวอย่างการใช้งานก็คือ เราอยากรู้ว่า มีบ้านไหนที่มีจำนวนห้องนอนแปลก ๆ มั้ย (เช่น 50 ห้องนอน หรือ -5 ห้องนอน) ก็หาค่า unique จากคอลัมน์ “bedrooms”\n",
    "dataframe['C1'].unique()\n",
    "\n",
    "\n",
    "## เช็คว่ามีแถวไหนข้อมูลซ้ำมั้ย (Duplicated)\n",
    "# อันนี้มีประโยชน์มาก เอาไว้ใช้เช็คว่ามีข้อมูลแปลก ๆ มั้ย เช่น ทุกคอลัมน์ซ้ำกันหมด (อันนี้มีโอกาสว่าเป็นข้อมูลซ้ำ อาจจะต้องลบออก) หรือซ้ำกันบางคอลัมน์ (อันนี้ต้องเช็คอีกทีว่าคืออะไร)\n",
    "dataframe.duplicated()                      # หาอันที่เหมือนกันทุกคอลัมน์\n",
    "dataframe.duplicated('C1')                  # หาอันที่ซ้ำกันเฉพาะคอลัมน์ C1\n",
    "dataframe.duplicated(['C1', 'C2'])          # หาอันที่ซ้ำกันเฉพาะคอลัมน์ C1 และ C2\n",
    "# ปกติแล้วถ้ามีไอเทมซ้ำ คำสั่งนี้จะไม่แสดงไอเทมแรกในกลุ่มที่ซ้ำ (เช่น ถ้า C1=5 มี 2 แถว มันจะแสดงเฉพาะแถวที่ 2) เราสามารถใส่ Argument keep=False เข้าไปเพื่อบังคับให้มันแสดงทุกแถวได้\n",
    "# นอกจากนั้นเรายังสามารถนับจำนวนแถวที่ Duplicate และลบทิ้งได้ด้วย\n",
    "\n",
    "\n",
    "## การนับจำนวน Duplicate\n",
    "len(df[ df.duplicated(['A', 'B', 'C'], keep = False) ])\n",
    "\n",
    "\n",
    "## การลบ Duplicate\n",
    "# เอาไว้ใช้ตอนเราเจอว่าทุกคอลัมน์ซ้ำกันหมดเลย ซึ่งเป็นเคสที่บอกว่าข้อมูลน่าจะซ้ำ ลบออกได้ (ขึ้นอยู่กับข้อมูลด้วยนะ บางข้อมูลอาจจะไม่ได้แปลว่าซ้ำแล้วลบได้)\n",
    "# โค้ดนี้เราต้อง reset index หลังลบ duplicate ด้วย\n",
    "df.drop_duplicates(['A', 'B', 'C'], inplace=True)       # Remove the duplicates\n",
    "df.reset_index(drop=True, inplace=True)                 # Reset dataframe index after drop_duplicates.\n",
    "len(df)\n",
    "\n",
    "\n",
    "## การลบแถว และลบคอลัมน์\n",
    "# ลบคอลัมน์สามารถทำได้แบบนี้\n",
    "dataframe = dataframe.drop('C1', axis=1)\n",
    "df.drop(['C1'], axis=1, inplace=True)               # แบบนี้ก็ได้\n",
    "df.drop(['C1', 'C2', 'C3'], 1, inplace=True)        # ลบทีละหลายคอลัมน์ก็ได้\n",
    "# ส่วนการลบแถวจะลำบากหน่อย เพราะต้องใส่ Row Index (เลขที่อยู่ซ้ายสุดเวลาเราปรินท์ DataFrame)\n",
    "dataframe = dataframe.drop(5, axis=0)\n",
    "dataframe.reset_index(drop=True)                    # Reset index\n",
    "# ลบแถวแล้วอย่าลืมเช็คด้วยว่าที่ลบไปถูกต้องมั้ย และหลังจากลบแถวต้อง Reset Index ด้วย\n",
    "\n",
    "\n",
    "## การลบแถวที่มี Missing Value\n",
    "# ข้อควรระวัง: การที่อยู่ๆ เราลบแถวที่มี Missing Value ทิ้งไปเลยอาจจะไม่ใช่วิธีที่ดีที่สุดในการทำ Data Analysis เสมอไปนะ บางเคสการ Impute (คำนวณหาค่าไปใส่) จะดีกว่า\n",
    "dataframe2 = dataframe.dropna(axis=0)\n",
    "\n",
    "\n",
    "## แทนค่า Missing Value ด้วยค่าเฉลี่ย (Mean Imputation)\n",
    "# วิธีหนึ่งในการแทนค่าที่หายไป คือการทำสิ่งที่เรียกว่า Mean Imputation หรือหาค่าเฉลี่ยของคอลัมน์นั้น แล้วเอามาแทนค่าที่หายไปนั่นเอง\n",
    "# ข้อดีของการทำ Mean Imputation คือ สามารถทำได้ง่าย แต่ก็ต้องระวังเรื่องข้อเสีย เช่น ทำแบบนี้จะเป็นการไม่สนใจความสัมพันธ์ระหว่างตัวแปร ทำให้เกิด Bias สูง ควรใช้เฉพาะเวลา Missing Value ไม่เยอะเท่านั้น\n",
    "# สามารถรันโค้ดด้านล่างเพื่อทำ Mean Imputation ได้ง่ายๆ เลย\n",
    "import numpy as np\n",
    "meanAge = np.mean(df.Age)               # Get mean value\n",
    "df.Age = df.Age.fillna(meanAge)         # Fill missing values with mean\n",
    "\n",
    "\n",
    "## การลูปข้อมูลแต่ละคอลัมน์ และแต่ละแถว\n",
    "# การลูปมีประโยชน์มากถ้าเราต้องการเขียนฟังก์ชั่นแปลก ๆ ใช้เองที่ Pandas ไม่รองรับ (หรืออาจจะรองรับแต่เราหาไม่เจอ เขียนเองง่ายกว่า) สามารถลูปได้ทั้งแต่ละคอลัมน์ และแต่ละแถว\n",
    "for col_idx,data in dataframe.iteritems():\n",
    "    print (\"column:\",col_idx)\n",
    "    print (\"column data:\")\n",
    "    print (data,\"\\n\")\n",
    "# การลูปข้อมูลแต่ละแถว\n",
    "for col_idx,data in dataframe.iterrows():\n",
    "    print (\"row:\",col_idx)\n",
    "    print (\"row data:\")\n",
    "    print (data,\"\\n\")\n",
    "\n",
    "\n",
    "## วิธีเปลี่ยน DataFrame จากแบบ Wide เป็น Long (Melt)\n",
    "# การ Melt Data มีประโยชน์มากเวลาเราต้องการเอาข้อมูลไปพลอต Data Visualization หรือเราต้องการ Aggregate\n",
    "dataframe2 = dataframe.melt()\n",
    "\n",
    "\n",
    "## วิธีการเปลี่ยนชื่อคอลัมน์ (Rename)\n",
    "# บางทีเราต้องการเปลี่ยนชื่อเพื่อให้สั้นลง ให้พิมพ์สะดวกขึ้น สามารถทำได้ดังนี้\n",
    "dataframe.rename(columns={'old':'new'},inplace=True)\n",
    "\n",
    "\n",
    "## วิธีการใส่คำนำหน้าคอลัมน์ (Prefix)\n",
    "# มีประโยชน์มากตอนเรามีข้อมูลหลาย ๆ ชุด และต้องการ Merge โดยอยากให้ชื่อคอลัมน์ไม่ซ้ำกัน\n",
    "thisdata = thisdata.add_prefix('data_')\n",
    "\n",
    "\n",
    "## วิธีการแทนค่าใน DataFrame\n",
    "# เหมาะมากเวลาต้องการแก้ Typo Error เช่น เราอยากได้ค่า Bangkok แต่เรารู้ว่ามีคนเขียนเป็น BKK อะไรแบบนี้ (รันคำสั่ง .unique เพื่อดูก่อน)\n",
    "# เราสามารถ Replace ทั้ง DataFrame ได้เลยแบบนี้\n",
    "dataframe2 = dataframe.replace(1, -100)\n",
    "# เราสามารถ Replace หลายค่าพร้อมกันได้ด้วยครับ และสามารถกำหนด Column ที่ต้องการให้แทนค่าได้ด้วย\n",
    "df['city'].replace({\n",
    "        'BKK':'Bangkok',\n",
    "        'BNK':'Bangkok'\n",
    "    }, inplace=True)\n",
    "\n",
    "\n",
    "## วิธีการ Export DataFrame เป็นไฟล์ CSV\n",
    "# หลังจากที่เราจัดการ Data เรียบร้อยแล้ว ก็สามารถ Export เป็น CSV เอาไปใช้ต่อกับโปรแกรมอื่น หรืองานส่วนอื่น ๆ ได้\n",
    "dataframe.to_csv('dataframe.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        10\n",
       "1        20\n",
       "2        30\n",
       "3        QA\n",
       "4    Iphone\n",
       "5      True\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.Series([1, 2, 3])\n",
    "data2 = pd.Series([10, 20, 30, \"QA\", \"Iphone\", True])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    20\n",
       "2    30\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items=['องุ่น', 'กล้วย', 'มะละกอ']\n",
    "idx=[50, 20, 30]\n",
    "ps=pd.Series(items, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.Series([10, 20, 30, \"QA\", \"Iphone\", True])\n",
    "data2[1:3] = data2[1:3].astype(str)\n",
    "print(data2[1:3])\n",
    "# ใช้ได้เฉพาะข้อมูลตัวเลขเท่านั้น"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
